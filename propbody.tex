
% Draft #2


% Main document

\bibliographystyle{plain}

\section*{Introduction, The Problem To Be Addressed}

In recent years, Moore's law has begun to plateau. As a result the hardware 
industry has increasingly been turning to MIMD and SIMD architectures as a 
solution.  Some of the highest performing SIMD implementations today are 
provided by GPUs and can be harnessed via GPGPU languages such as CUDA and 
OpenCL.  However, taking advantage of GPGPU is hard as it requires knowledge of 
the low-level concepts of these languages. It is also not portable between 
different hardware and methods of concurrency.

Structured grids are a common computational pattern for scientific parallel 
computation. They allow us to specify \emph{stencils} or \emph{kernels} which 
are local computations that compute a new value from neighboring cells.  
Stencils are promoted to operations over the whole array by application to 
every index.  Many algorithms can be described in this way including the 
Gaussian blur filter, edge detection as well as scientific applications such as 
fluid dynamics. It is also possible to highly parallelize this computation by 
splitting the grid into smaller chunks and running the stencil on each 
separately.

Ypnos \cite{ypnos} is an Embedded Domain Specific Language in the Haskell 
programming language that is capable of describing and running these kernels 
over a grid.  It defines a syntax and various primitives for the structured 
grid computation.  

A kernel is described using a modified Haskell function syntax. The following 
is a kernel used to compute the Gaussian of a grid. The arguments are written 
as a grid and the central point is annotated with \verb|@|. It also denotes the 
location where the kernels return value is written in the new grid.

\begin{verbatim}
ave2D :: Grid (X * Y) Double -> Double
ave2D (X * Y): | _  t _ | = (t+l+c+r+b)/5.0
               | l @c r |
               | _  b _ |
\end{verbatim}

The \emph{run} primitive is used to lift the stencil to a grid operation and 
\emph{iterate} primitive simply recursively applies run. The \emph{reduce} 
primitive allows us to summarise the data so that we can calculate means, sums, 
minimums or maximums. This result is often used as a stopping condition for 
iteration.

The \emph{zip} and \emph{unzip} primitives allow us to pair and unpair the 
values of two grids respectively. This is useful when dealing with multiple 
inter-related quantities as is the case in a physical system with force, 
acceleration and velocity.

Due to the declarative syntax and its purity the order of application of the 
stencils is not important. The author of an Ypnos program does not need to 
worry about the method of concurrency underpinning their program. This allows 
the implementers of Ypnos to use whichever method is most appropriate for the 
given work load and computer. As many computers these days are equipped with 
very advanced GPUs capable of general purpose computation, the Ypnos language 
should be able to use these to accelerate its calculations.

\section*{Starting Point}

\begin{itemize}

\item I have had experience of functional programming from the course as well 
as having completed some Haskell tutorials. 

\item I have experience of building a compiler from Part IB supervision work.

\item During the course of an 11 week internship I learnt to plan, implement, 
document and test my own project.

\item I have already read the Ypnos paper and am familiar with the constructs 
of the language as well its primitives.

\item At present Ypnos has been partially implemented in a single threaded 
fashion on the CPU. The proof-of-concept is only partially implemented. This 
implementation can be taken as both the starting point and the benchmark for 
the new implementation.

\item A Haskell ESDL already exists for compiling array computations to CUDA 
code. The library, ``accelerate'' \cite{accel}, takes an AST and produces code
to run on the GPU.  I will use this library as a back-end to avoid writing a 
compiler to CUDA code directly.

\end{itemize}

\section*{Resources Required}

\begin{itemize} 

\item For this project I shall require my own laptop computer that runs Arch 
Linux for the bulk of development work. 

\item Backup will be to github, the SRCF and/or the MCS. Should my computer 
fail I will be able to use the MCS computers for the project.

\item I require an Nvidia GPU in order to test the code produced. This will be 
provided by Dominic Orchard and I will have access to the machine via SSH for 
testing purposes.

\end{itemize}

\section*{Work to be done}

The project breaks down into the following sub-projects:

\begin{enumerate}

\item Write unit tests that can be used to check the correctness of my 
implementation. The tests will cover micro aspects of the programming language 
such as: constants, unary application, binary application, indexing, 
conditionals, local let-binding, etc.

\item The implementation of the main compilation. This involves writing a 
compilation pass that can take the Ypnos AST and produce a correspondent 
``accelerate'' AST.

\item The implementation of the basic \emph{run} and \emph{reduce} primitives 
as well as any combinators for constructing and deconstructing arrays from raw 
data. The combinators may be written in the ``accelerate'' language directly.

\item The testing of the implementation to check that it works correctly and is 
faster than the original modulo data copying. This will need a test bench to be 
constructed that includes various well know stencil computations. The test 
bench will include the following programs as a minimum: the Game of Life, 
Gaussian blur, Canny edge detection, and (if zip/unzip are implemented) the 
difference of Gaussians.

\end{enumerate}

\section*{Success Criterion for the Main Result}

The project will be a success if:

\begin{enumerate}

\item It can compile Ypnos code and implements the \emph{run} primitive on the 
GPU.

\item It implements the \emph{reduce} primitive on the GPU.

\item It scales better than the current single threaded implementation on large 
work loads. That is to say that when the domain size is increased, the 
difference in computation time increases too. However, this must take into 
account the time required to copy data on and off the GPU.

\item It does all of the above correctly and passes the initial unit tests.

\end{enumerate}

\section*{Possible Extensions}

If the main aim for this project is achieved then I shall try to implement 
further primitives of the Ypnos language. The programmer will then be able to 
take advantage of the speed gains of the GPU pipeline. I will attempt them in 
this order:

\begin{enumerate}

\item The ``iterate'' primitive. This will eliminate the need to copy data 
between the CPU and GPU at each step.

\item The ``zip'' primitive.

\end{enumerate}

I may also attempt to enhance the compiler to decide at compile-time whether to 
use the GPU or CPU dependant on the size of computation required.

\section*{Timetable: Workplan and Milestones to be achieved.}

Planned starting date is 19/10/2011 when the proposal is accepted.

\subsection*{Michaelmas weeks 2-4} Learn to write and read Haskell code. Write 
some programs in Ypnos. Try to understand the existing code base. Start writing 
a unit testing suite.

\subsection*{Michaelmas weeks 5-6} Finish writing the unit testing suite by 
including Gaussian blur and Game of Life programs. Get familiar with the 
``accelerate'' ESDL by reading the paper and writing some toy programs. 

\subsection*{Michaelmas weeks 7-8} Start implementation of the compiler from 
the Ypnos AST to the ``accelerate'' AST. Most basic operations should translate 
correctly by this point.

\subsection*{Michaelmas vacation} Finish the compiler and begin work on 
implementing the run and reduce primitives.

\subsection*{Lent weeks 0-2} Finish the primitives if necessary. Write the 
progress report. Start work on the basic test bench.

\subsection*{Lent weeks 3-5} Finalise the main test bench and run experiments.  
Analyse the performance and scalability of the approach. Make improvements to 
the code as necessary to achieve the main aim of the project. 

\subsection*{Lent weeks 6-8} If there is time then the main extensions may be 
implemented at this point.

\subsection*{Easter vacation} Write the main chapters of the dissertation.

\subsection*{Easter term 0-2} Elaborate on the existing tests bench and run 
final experiments. Complete the dissertation.

\subsection*{Easter term 3} Proof reading and then an early submission.  

\bibliography{refs}
